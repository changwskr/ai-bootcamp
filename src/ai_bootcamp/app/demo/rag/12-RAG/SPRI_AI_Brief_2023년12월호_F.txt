Ⅰ. 인공지능 산업 동향 브리프
1. 정책/법제
 ▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 ························· 1
 ▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의 ··························· 2
 ▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언 ··························· 3
 ▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각 ····································· 4
 ▹ 미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출 ················· 5
 ▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항 ··················································· 6
2. 기업/산업
 ▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성 ································ 7
 ▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ······································· 8
 ▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································ 9
 ▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10
 ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11
 ▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망 ··········································· 12
 ▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망 ································ 13
 ▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화 ···························································· 14
3. 기술/연구
 ▹ 영국 과학혁신기술부, AI 안전 연구소 설립 발표 ······························································ 15
 ▹ 구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표 ······························ 16
 ▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수 ··········································· 17
 4. 인력/교육
 ▹ 영국 옥스퍼드 인터넷 연구소, AI 기술자의 임금이 평균 21% 높아 ······························· 18


 Ⅰ. 인공지능 산업 동향 브리프
 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표
n 미국 바이든 대통령이 ‘안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령’에 서명하고
광범위한 행정 조치를 명시
n 행정명령은 △AI의 안전과 보안 기준 마련 △개인정보보호 △형평성과 시민권 향상 △소비자
보호 △노동자 지원 △혁신과 경쟁 촉진 △국제협력을 골자로 함
KEY Contents
£ 바이든 대통령, AI 행정명령 통해 안전하고 신뢰할 수 있는 AI 개발과 활용 추진
n 미국 바이든 대통령이 2023년 10월 30일 연방정부 차원에서 안전하고 신뢰할 수 있는 AI 개발과
사용을 보장하기 위한 행정명령을 발표
∙ 행정명령은 △AI의 안전과 보안 기준 마련 △개인정보보호 △형평성과 시민권 향상 △소비자 보호
△노동자 지원 △혁신과 경쟁 촉진 △국제협력에 관한 내용을 포괄
n (AI 안전과 보안 기준) 강력한 AI 시스템을 개발하는 기업에게 안전 테스트 결과와 시스템에 관한
주요 정보를 미국 정부와 공유할 것을 요구하고, AI 시스템의 안전성과 신뢰성 확인을 위한 표준 및
AI 생성 콘텐츠 표시를 위한 표준과 모범사례 확립을 추진
∙ △1026 플롭스(FLOPS, Floating Point Operation Per Second)를 초과하는 컴퓨팅 성능 또는 생물학적
서열 데이터를 주로 사용하고 1023플롭스를 초과하는 컴퓨팅 성능을 사용하는 모델 △단일 데이터센터에서
1,000Gbit/s 이상의 네트워킹으로 연결되며 AI 훈련에서 이론상 최대 1020 플롭스를 처리할 수 있는
컴퓨팅 용량을 갖춘 컴퓨팅 클러스터가 정보공유 요구대상
n (형평성과 시민권 향상) 법률, 주택, 보건 분야에서 AI의 무책임한 사용으로 인한 차별과 편견 및 기타
문제를 방지하는 조치를 확대
∙ 형사사법 시스템에서 AI 사용 모범사례를 개발하고, 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한
지침을 제공하며, 보건복지 부문에서 책임 있는 AI 배포와 사용을 위한 전략을 마련
n (소비자 보호와 근로자 지원) 의료 분야에서 책임 있는 AI 사용을 촉진하고 맞춤형 개인교습 등 학교
내 AI 교육 도구 관련 자원을 개발하며, AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과
모범사례를 마련
n (혁신과 경쟁 촉진) 국가AI연구자원(National Artificial Intelligence Research Resource, NAIRR)*을
통해 미국 전역의 AI 연구를 촉진하고, 중소기업과 개발자에 기술과 인프라를 지원
* 국가 차원에서 AI 연구 인프라를 확충해 더 많은 AI 연구자에게 인프라를 지원하는 프로그램 ∙ 비자 기준과 인터뷰 절차의 현대화와 간소화로 AI 관련 주요 분야의 전문 지식을 갖춘 외국인들이 미국에서
공부하고 취업할 수 있도록 지원
☞ 출처 : The White House, Executive Order on the Safe, Secure, and Trustworthy Develop

G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의
n G7이 첨단 AI 시스템을 개발하는 기업을 대상으로 AI 위험 식별과 완화를 위해 자발적인
채택을 권고하는 AI 국제 행동강령을 마련
n 행동강령은 AI 수명주기 전반에 걸친 위험 평가와 완화, 투명성과 책임성의 보장, 정보공유와
이해관계자 간 협력, 보안 통제, 콘텐츠 인증과 출처 확인 등의 조치를 요구
KEY Contents
£ G7, 첨단 AI 시스템의 위험 관리를 위한 국제 행동강령 마련
n 주요 7개국(G7)*은 2023년 10월 30일 ‘히로시마 AI 프로세스’를 통해 AI 기업 대상의 AI 국제
행동강령(International Code of Conduct for Advanced AI Systems)에 합의
∙ G7은 2023년 5월 일본 히로시마에서 개최된 정상회의에서 생성 AI에 관한 국제규범 마련과
정보공유를 위해 ‘히로시마 AI 프로세스’를 출범** ∙ 기업의 자발적 채택을 위해 마련된 이번 행동강령은 기반모델과 생성 AI를 포함한 첨단 AI 시스템의
위험 식별과 완화에 필요한 조치를 포함
* 주요 7개국(G7)은 미국, 일본, 독일, 영국, 프랑스, 이탈리아, 캐나다를 의미
** 5월 정상회의에는 한국, 호주, 베트남 등을 포함한 8개국이 초청을 받았으나, AI 국제 행동강령에는 우선 G7 국가만 포함하여 채택
n G7은 행동강령을 통해 아래의 조치를 제시했으며, 빠르게 발전하는 기술에 대응할 수 있도록
이해관계자 협의를 통해 필요에 따라 개정할 예정
∙ 첨단 AI 시스템의 개발 과정에서 AI 수명주기 전반에 걸쳐 위험을 평가 및 완화하는 조치를 채택하고, 첨단 AI 시스템의 출시와 배포 이후 취약점과 오용 사고, 오용 유형을 파악해 완화
∙ 첨단 AI 시스템의 성능과 한계를 공개하고 적절하거나 부적절한 사용영역을 알리는 방법으로 투명성을
보장하고 책임성을 강화
∙ 산업계, 정부, 시민사회, 학계를 포함해 첨단 AI 시스템을 개발하는 조직 간 정보공유와 사고 발생 시
신고를 위해 협력하고, 위험 기반 접근방식을 토대로 개인정보보호 정책과 위험 완화 조치를 포함하는
AI 거버넌스와 위험 관리 정책을 마련
∙ AI 수명주기 전반에 걸쳐 물리보안, 사이버보안, 내부자 위협 보안을 포함한 강력한 보안 통제 구현
∙ 사용자가 AI 생성 콘텐츠를 식별할 수 있도록 워터마크를 비롯하여 기술적으로 가능한 기법으로
신뢰할 수 있는 콘텐츠 인증과 출처 확인 메커니즘을 개발 및 구축 ∙ 사회적 위험과 안전·보안 문제를 완화하는 연구와 효과적인 완화 대책에 우선 투자하고, 기후 위기
대응, 세계 보건과 교육 등 세계적 난제 해결을 위한 첨단 AI 시스템을 우선 개발
∙ 국제 기술 표준의 개발 및 채택을 가속화하고, 개인정보와 지식재산권 보호를 위해 데이터 입력과 수집
시 적절한 보호 장치 구현

영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언
n 영국 블레츨리 파크에서 개최된 AI 안전성 정상회의에 참가한 28개국들이 AI 안전 보장을
위한 협력 방안을 담은 블레츨리 선언을 발표
n 첨단 AI를 개발하는 국가와 기업들은 AI 시스템에 대한 안전 테스트 계획에 합의했으며, 영국의 AI 안전 연구소가 전 세계 국가와 협력해 테스트를 주도할 예정
KEY Contents
£ AI 안전성 정상회의 참가국들, 블레츨리 선언 통해 AI 안전 보장을 위한 협력에 합의
n 2023년 11월 1~2일 영국 블레츨리 파크에서 열린 AI 안전성 정상회의(AI Safety Summit)에
참가한 28개국 대표들이 AI 위험 관리를 위한 ‘블레츨리 선언’을 발표 ∙ 선언은 AI 안전 보장을 위해 국가, 국제기구, 기업, 시민사회, 학계를 포함한 모든 이해관계자의 협력이
중요하다고 강조했으며, 특히 최첨단 AI 시스템 개발 기업은 안전 평가를 비롯한 적절한 조치를 취하여
AI 시스템의 안전을 보장할 책임이 있다고 지적
∙ 각국은 AI 안전 보장을 위해 첨단 AI 개발기업의 투명성 향상, 적절한 평가지표와 안전 테스트 도구
개발, 공공부문 역량 구축과 과학 연구개발 등의 분야에서 협력하기로 합의
£ 영국 총리, 정부 주도의 첨단 AI 시스템 안전 테스트 계획 발표
n 리시 수낙 영국 총리는 AI 안전성 정상회의를 마무리하며 첨단 AI 모델에 대한 안전성 시험 계획
수립과 테스트 수행을 주도할 영국 AI 안전 연구소의 출범을 발표
∙ 첨단 AI 모델의 안전 테스트는 국가 안보와 안전, 사회적 피해를 포함한 여러 잠재적 유해 기능에 대한
시험을 포함하며, 참석자들은 정부 주도의 외부 안전 테스트에 합의
∙ 각국 정부는 테스트와 기타 안전 연구를 위한 공공부문 역량에 투자하고, 테스트 결과가 다른 국가와
관련된 경우 해당 국가와 결과를 공유하며, 적절한 시기에 공동 표준 개발을 위해 노력하기로 합의
n 참가국들은 튜링상을 수상한 AI 학자인 요슈아 벤지오 교수가 주도하는 ‘과학의 현황(State of
the Science)’ 보고서 작성에도 합의했으며, 보고서를 통해 첨단 AI의 위험과 가능성에 관한
기존 연구를 과학적으로 평가하고 향후 AI 안전 연구를 위한 우선순위를 제시할 계획
n 한국은 영국 정부와 6개월 뒤에 온라인으로 AI 미니 정상회의를 공동 개최하기로 합의했으며, 프랑스 정부와는 1년 후 대면 정상회의를 개최할 예정
☞ 출처: Gov.uk, The Bletchley Declaration by Countries Attending the AI Safety Summit, 1-2 November 2023, 2023.11.01.
Gov.uk, World leaders, top AI companies set out plan for safety testing of frontier as first global AI Safety

미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각
n 미국 캘리포니아 북부지방법원은 미드저니, 스태빌리티AI, 디비언트아트를 대상으로 예술가
3인이 제기한 저작권 침해 소송을 기각
n 법원은 기각 이유로 고소장에 제시된 상당수 작품이 저작권청에 등록되지 않았으며, AI로
생성된 이미지와 특정 작품 간 유사성을 입증하기 어렵다는 점을 제시
KEY Contents
£ 예술가들의 AI 저작권 침해 소송, 저작권 미등록과 증거불충분으로 기각
n 미국 캘리포니아 북부지방법원의 윌리엄 오릭(William Orrick) 판사는 2023년 10월 30일 미드저니(Midjourney), 스태빌리티AI(Stability AI), 디비언트아트(DeviantArt)에 제기된 저작권 침해 소송을 기각∙ 2023년 1월 예술가 사라 앤더슨(Sarah Anderson), 캘리 맥커넌(Kelly McKernan), 칼라
오르티즈(Karla Ortiz)는 이미지 생성 AI 서비스를 개발한 3개 기업을 상대로 저작권 침해 소송을 제기∙ 예술가들은 3개 기업이 AI 모델을 학습시키기 위해 원작자 동의 없이 작품을 학습 데이터셋에
포함하여 저작권을 침해했다고 주장했으며, 법원은 지난 4월 피소 기업들이 제출한 기각 신청을
수용해 소송을 기각
n 오릭 판사는 판결문에서 소송을 기각한 핵심 이유로 예술가들의 저작권 미등록을 제시
∙ 판결문은 소송을 제기한 캘리 맥커넌과 칼라 오르티즈가 미국 저작권청에 예술 작품에 대한 저작권을
제출하지 않았다는 점을 지적했으며, 사라 앤더슨은 고소장에 인용된 수백 개의 작품 중 16개 작품에
대해서만 저작권을 보유
n 판결문은 또한 생성 AI 모델 훈련에 사용된 모든 이미지에 저작권이 있다거나, 생성 AI로 만든
이미지가 저작물을 이용해 훈련되었으므로 저작물의 파생 이미지라는 주장은 개연성이 부족하다고지적
∙ AI는 새로운 이미지를 생성할 때 다양한 예술가의 작품을 참조하므로, 생성된 이미지와 저작권을 가진
특정 작품과의 실질적 유사성을 입증할 수 없다면 저작권 침해를 인정받기 어려움
n 오릭 판사는 원고 측에 고소장을 수정하고 저작권이 침해된 특정 이미지를 중심으로 소송 범위를
줄여 소송을 다시 제기할 것을 요청
∙ 단, 사라 앤더슨이 저작권을 보유한 16개 작품을 무단으로 복제한 스태빌리티AI에 대한 저작권 침해
소송은 인정되어 계속 진행됨
☞ 출처: Venturebeat, Midjourney, Stability AI and DeviantArt win a victory in copyright

미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출
n 미국 FTC는 저작권청이 실시한 저작권과 AI 관련 질의공고에 대하여 소비자 보호와 경쟁
측면의 의견을 제시
n FTC는 생성 AI로 인한 창작자와 소비자 피해의 가능성에 우려를 표시하는 한편, 일부
빅테크가 막대한 재원을 활용해 시장 지배력을 더욱 강화할 수 있다는 우려를 제기
KEY Contents
£ FTC, 생성 AI로 인한 소비자와 창작자의 피해 및 빅테크의 시장 지배력 강화 우려
n 미국 연방거래위원회(FTC)가 2023년 10월 30일 저작권청(U.S. Copyright Office, USCO)이
지난 9월 발표한 저작권과 AI 관련 질의공고(Notice of Inquiry, NOI)에 대한 의견서를 발표∙ 저작권청은 생성 AI와 관련된 저작권법과 정책 이슈를 조사하고 있으며, 폭넓은 의견 수렴을 통해
입법과 규제 조치의 필요성을 검토할 계획
∙ FTC는 생성 AI의 개발과 배포가 소비자, 근로자, 중소기업에 피해를 줄 수 있다며 소비자의 개인정보
침해, 차별과 편견의 자동화, 사기 범죄 등 AI 사용과 관련된 위험에 주목
n FTC는 저작권법에 따른 권리와 책임 범위를 넘어서는 저작권 문제에 주목하여 생성 AI로 인해
창작자의 경쟁력이 불공정한 피해를 볼 수 있으며, 소비자가 특정 창작자의 작품을 생성 AI가
만들었다고 오해할 소지가 있다고 지적
∙ 저작권법에 저촉되는 행위는 불공정 경쟁이나 기만행위에도 해당될 수 있으며, 창작자의 평판 악화, 저작물의 가치 저하나 개인정보 유출로 소비자에 상당한 피해를 초래 가능
n FTC는 일부 빅테크가 막대한 재원을 활용해 생성 AI 사용자의 이탈을 막고 저작권이 있는 상용
데이터에 대한 독점 라이선스를 확보해 시장 지배력을 더욱 강화할 수 있다는 우려도 제기∙ 이와 관련 FTC는 아마존 AI 비서 ‘알렉사(Alexa)’와 스마트홈 보안 기기 ‘링(Ring)’이 소비자의 사적
정보를 알고리즘 훈련에 사용하여 프라이버시를 침해한 혐의를 조사하는 등 법적 권한을 활용해 AI
관련 불법 행위에 대처하고 있음
* FTC는 2023년 5월 31일 동의를 받지 않고 어린이들의 음성과 위치 정보를 활용한 ‘알렉사’와 고객의 사적 영상에 대하여
직원에게 무제한 접근 권한을 부여한 ‘링’에 3,080만 달러(약 420억 원)의 과징금을 부과
n FTC는 빠르게 발전하는 생성 AI가 여러 산업과 비즈니스에 변화를 가져올 수 있지만, 현행법상
AI에 관한 예외 조항은 없다며, 모든 권한을 활용해 소비자를 보호하고 개방적이고 공정한 경쟁
시장을 유지하겠다고 강조
☞ 출처: FTC, In Comment Submitted to U.S. Copyright Office, FTC Raises AI-related Competition and
Consumer Protection Issues, Stressing That It Will Use Its Authority to Protect C


