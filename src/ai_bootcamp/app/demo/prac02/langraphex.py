#!/usr/bin/env python3
"""
LangGraph ì˜ˆì œ
LangGraphë¥¼ ì‚¬ìš©í•œ ì›Œí¬í”Œë¡œìš° ë°ëª¨ (OpenAI API ì—°ë™)
"""

import logging
import os
from typing import TypedDict
from langgraph.graph import StateGraph
from openai import OpenAI
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ìƒíƒœ ì •ì˜
class WorkflowState(TypedDict):
    query: str
    result: str
    summary: str


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("IN: main() - LangGraph ì˜ˆì œ ì‹œì‘")
    
    try:
        # ê·¸ë˜í”„ ìƒì„±
        workflow = StateGraph(WorkflowState)
        
        # ë…¸ë“œ ì •ì˜
        def search_node(state):
            logger.info(f"IN: search_node() - OpenAI API í˜¸ì¶œ: query={state['query']}")
            try:
                # OpenAI API í˜¸ì¶œ
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ìì„¸í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": state['query']}
                    ],
                    max_tokens=500,
                    temperature=0.7
                )
                result = response.choices[0].message.content
                logger.info(f"OUT: search_node() - OpenAI API ì‘ë‹µ ì™„ë£Œ: {result[:100]}...")
                return {"result": result}
            except Exception as e:
                logger.error(f"OUT: search_node() - OpenAI API ì˜¤ë¥˜: {e}")
                error_msg = f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                return {"result": error_msg}
        
        def summarize_node(state):
            logger.info(f"IN: summarize_node() - ìš”ì•½ ì‹¤í–‰: result={state['result'][:100]}...")
            try:
                # OpenAI APIë¡œ ìš”ì•½ ìƒì„±
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”:\n\n{state['result']}"}
                    ],
                    max_tokens=200,
                    temperature=0.5
                )
                summary = response.choices[0].message.content
                logger.info(f"OUT: summarize_node() - ìš”ì•½ ì™„ë£Œ: {summary[:100]}...")
                return {"summary": summary}
            except Exception as e:
                logger.error(f"OUT: summarize_node() - OpenAI API ì˜¤ë¥˜: {e}")
                error_msg = f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                return {"summary": error_msg}
        
        # ë…¸ë“œ ë“±ë¡
        workflow.add_node("search", search_node)
        workflow.add_node("summarize", summarize_node)
        
        # ì—°ê²° ì •ì˜
        workflow.add_edge("search", "summarize")
        
        # ì‹œì‘ì  ì„¤ì • (STARTì—ì„œ searchë¡œ)
        workflow.set_entry_point("search")
        
        # ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼
        app = workflow.compile()
        logger.info("OUT: main() - ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼ ì™„ë£Œ")
        
        print("=" * 60)
        print("ğŸ¯ LangGraph + OpenAI API ì›Œí¬í”Œë¡œìš° ë°ëª¨")
        print("=" * 60)
        print("ğŸ’¡ ì‚¬ìš©ë²•:")
        print("   - ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ OpenAI APIë¡œ ë‹µë³€ â†’ ìš”ì•½ ì›Œí¬í”Œë¡œìš°ê°€ ì‹¤í–‰ë©ë‹ˆë‹¤")
        print("   - 'END'ë¥¼ ì…ë ¥í•˜ë©´ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë©ë‹ˆë‹¤")
        print("ğŸ”‘ OpenAI API Key í•„ìš”: .env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì •")
        print("=" * 60)
        
        # ëŒ€í™”í˜• ë£¨í”„
        while True:
            try:
                # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
                user_input = input("\nğŸ¤” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: END): ").strip()
                
                # END ì…ë ¥ ì‹œ ì¢…ë£Œ
                if user_input.upper() == "END":
                    logger.info("IN: main() - ì‚¬ìš©ìê°€ ENDë¥¼ ì…ë ¥í•˜ì—¬ ì¢…ë£Œ")
                    print("\nğŸ‘‹ LangGraph ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                    break
                
                # ë¹ˆ ì…ë ¥ ì²˜ë¦¬
                if not user_input:
                    print("âš ï¸  ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue
                
                logger.info(f"IN: main() - ì‚¬ìš©ì ì…ë ¥: {user_input}")
                
                # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
                result = app.invoke({"query": user_input})
                logger.info(f"OUT: main() - ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ: {result}")
                
                # ê²°ê³¼ ì¶œë ¥
                print("\n" + "=" * 50)
                print("ğŸ¯ OpenAI API ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼")
                print("=" * 50)
                print(f"ğŸ“ ì›ë³¸ ì¿¼ë¦¬: {result['query']}")
                print(f"ğŸ¤– OpenAI ë‹µë³€: {result['result']}")
                print(f"ğŸ“‹ AI ìš”ì•½: {result['summary']}")
                print("=" * 50)
                
            except KeyboardInterrupt:
                logger.info("IN: main() - Ctrl+Cë¡œ ì¢…ë£Œ")
                print("\n\nğŸ‘‹ í”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                break
            except Exception as e:
                logger.error(f"OUT: main() - ë£¨í”„ ë‚´ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        
    except Exception as e:
        logger.error(f"OUT: main() - ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
